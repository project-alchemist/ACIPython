{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alchemist: A Python <=> MPI Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the Alchemist tutorial by playing around with its Python interface. The Python interface itself is running on a single core, but connects to Alchemist, which is running on multiple machines/cores, to do its distributed computations.\n",
    "\n",
    "Let us use Alchemist to perform some distributed operation on a dataset. In line with what we have seen in the tutorials for the Ristretto package, we will compute the first 200 singular values of a large dataset, the 36GB ocean temperature HDF5 file. In Ristretto we saw how we can do this by loading chunks of the data into memory, in this case we will be sending the data to Alchemist (in chunks), and then we will fetch the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Alchemist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start Alchemist:\n",
    "\n",
    "1) In the Jupyter tab in your browser (the one to the left of this one), click on 'new' on the top right\n",
    "\n",
    "2) Select 'Terminal' under 'Other' - this will open a new tab with a terminal \n",
    "\n",
    "3) Enter 'cd /usr/local/Alchemist'\n",
    "\n",
    "4) Enter './start.sh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will start Alchemist on your machine. You should see some preamble, concluding with \"Accepting connections ...\". This means that Alchemist is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Alchemist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now ignore the terminal and work in this notebook. First, let us load some dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alchemist import *\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to start an AlchemistSession instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = AlchemistSession()                  # Start AlchemistSession instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Alchemist server at address \"0.0.0.0\" and port 24960. \n",
    "\n",
    "Note 1: The Alchemist server would normally not be running locally.\n",
    "\n",
    "Note 2: The Alchemist interface would usually read this information automatically from a file provided by the network administrator, but for the purposes of this tutorial we input the information directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"0.0.0.0\"\n",
    "port = 24960                     # Enter the correct port number here\n",
    "\n",
    "als.connect_to_alchemist(address, port)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're connected to Alchemist, we need to request some workers. In general, if Alchemist is running on N nodes, then one of those will be the driver node, so there will be N-1 worker nodes. Some of these nodes could be used by other jobs, so we can ask Alchemist to list the status of the workers using the 'list_alchemist_workers()' command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als.list_alchemist_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All nodes are currently available, which shouldn't be all too surprising since nobody else is using this particular Alchemist instance. Let's request some available workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 2                         # Try a sensible number of workers here\n",
    "\n",
    "als.request_workers(num_workers)        # Request 'num_workers' workers from Alchemist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by the output, the interface automatically connects to the allocated workers. \n",
    "\n",
    "This isn't necessary, but we can check the connection by sending a test string from each workers and displaying the response by Alchemist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als.workers.send_test_string()          # Send test string and display response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and sending it to Alchemist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to load some data and have Alchemist work on it. We'll be using the 'sstHD.hdf5' dataset used in the Ristretto tutorial. The 'read_from_hdf5' function in ALchemist requires the file name as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read H5 file\n",
    "file_name = \"/Users/kai/Downloads/NEON-DS-Imaging-Spectrometer-Data.h5\"\n",
    "# file_name = \"/mnt/data/sstHD.hdf5\"\n",
    "\n",
    "f = als.read_from_hdf5(file_name)                # Fix this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's only one dataset in this particular HDF5 file, called 'sstHD', so let's extract it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sstHD = f['sstHD']\n",
    "sstHD = np.float64(f['Reflectance'][:,:,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can now be sent from the interface to Alchemist for processing. As before, it is assumed to be too large to fit in memory, so behind the scenes the dataset is split up into chunks and sent to Alchemist in pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alA = als.send_hdf5(sstHD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a dataset gets sent to Alchemist, a matrix handle gets returned, in this case called 'alA'. This matrix handle includes meta-data such as the ID assigned to the dataset by Alchemist and the dimensions of the dataset. We can see this information using the handle's 'meta' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alA.meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have successfully sent an HDF5 dataset to Alchemist! Now we can do something with it, but before that, we need to tell Alchemist what library has the MPI-based function that we want to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Alchemist, we must have one or more MPI-based libraries in mind. We tell Alchemist to load the library using the 'load_library' command. \n",
    "\n",
    "Behind the scenes, every MPI-based library that Alchemist has access to is interfaced with an Alchemist-Library Interface (ALI), which is a shared object file that is loaded dynamically at run time by the workers allocated to the current job. In our case, we have 'num_workers' workers assigned to this job, and only these workers load the requested library. But we, as users, don't have to worry about any of this.\n",
    "\n",
    "For the purposes of this tutorial, there is just one library available, a little testing library called 'TestLib' that has the distributed SVD implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_name = \"TestLib\"\n",
    "\n",
    "testlib = als.load_library(lib_name)    # The allocated workers load the library 'TestLib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What gets returned here is a handle to the library that we have called 'testlib' in this case. This handle provides the Alchemist interface with meta-data about the library, such as available methods and their input and output parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a task on Alchemist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally run the SVD ... again! Because we clearly didn't get enough of it in the Ristretto tutorial.\n",
    "\n",
    "The 'truncated_SVD' method is in the 'TestLib' library. AlchemistSession has a method 'run_task' that takes in the library handle, the name of the method as a string, and a variable length list of parameters that are the input parameters for the method. \n",
    "\n",
    "In the case of the 'truncated_SVD' method, it must know what matrix to operate on, and the number of singular values it should compute (called the 'rank'), and these need to be provided, in that order. \n",
    "\n",
    "The output of 'run_task' is a tuple with all the output parameters of the method. In the case of the SVD, these are the factors U and V, and the singular values (stored in the vector S). But we're not ready to receive all the output, nor would we necessarily want to have all of it. Alchemist instead returns matrix handles to all output matrices, so in this case we'd have the matrix handles 'alU', 'alS', and 'alV'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_handle = testlib\n",
    "method_name = \"truncated_SVD\"\n",
    "mat_handle = alA\n",
    "k = 20\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "print(\"hello\")\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "alU, alS, alV = als.run_task(lib_handle, method_name, mat_handle, k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll pretend that we're only interested in the first k singular values, so we'll ignore the matrix handles to U and V. \n",
    "\n",
    "To get Alchemist to send the data to us, we call AlchemistSession's 'get_array' method with the appropriate matrix handle (in this case, 'alS')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = als.get_array(alS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now do whatever we want with these first k singular values. Let's plot them using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'S' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-747579cd8d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'S' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(S)\n",
    "\n",
    "plt.plot(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask Alchemist to return subarrays to us. Let's ask it to return only the first 5 singular values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'als' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b902b5c7daa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'als' is not defined"
     ]
    }
   ],
   "source": [
    "S = als.get_array(alS, rows=range(k-5,k))\n",
    "\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disconnecting from and stopping Alchemist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done with Alchemist, it is important to stop the AlchemistSession instance using the 'stop()' command. This disconnects from Alchemist and frees up resources that Alchemist can then allocate to other jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done with the current instance of Alchemist, so let us go back to the terminal in the other tab and stop this instance of Alchemist. There isn't an elegant way of stopping Alchemist (at least not from this interface), so we're going to have to kill it using brute force (i.e. Ctrl-C).\n",
    "\n",
    "The intention is for Alchemist to keep running and be available for other jobs, but for the purposes of this tutorial, we're done with this instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any questions regarding Alchemist, e-mail kai.rothauge@berkeley.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
